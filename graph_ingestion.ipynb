{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb3b998d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸš€ STARTING NEO4J DATA INGESTION\n",
      "================================================================================\n",
      "\n",
      "ðŸ—‘ï¸  Clearing existing data...\n",
      "  âœ… Database cleared\n",
      "\n",
      "================================================================================\n",
      "PHASE 1: INGESTING NODES\n",
      "================================================================================\n",
      "\n",
      "ðŸ¢ Ingesting Companies...\n",
      "  âœ… 500 companies ingested\n",
      "\n",
      "ðŸ‘® Ingesting Auditors...\n",
      "  âœ… 10 auditors ingested\n",
      "\n",
      "ðŸ’¼ Ingesting Shareholders...\n",
      "  âœ… 250 shareholders ingested\n",
      "\n",
      "ðŸ“„ Ingesting Invoices...\n",
      "  âœ… 1500 invoices ingested\n",
      "\n",
      "================================================================================\n",
      "PHASE 2: CREATING RELATIONSHIPS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“ˆ Creating OWNS_SHARE relationships...\n",
      "  âœ… 1777 OWNS_SHARE relationships created\n",
      "\n",
      "ðŸ” Creating AUDITED_BY relationships...\n",
      "  âœ… 500 AUDITED_BY relationships created\n",
      "\n",
      "ðŸ“¤ Creating ISSUES_TO relationships...\n",
      "  âœ… 1500 ISSUES_TO relationships created\n",
      "\n",
      "ðŸ’³ Creating PAYS relationships...\n",
      "  âœ… 1490 PAYS relationships created\n",
      "\n",
      "ðŸ¢ Creating SUBSIDIARY_OF relationships...\n",
      "  ðŸ“‹ Columns in subsidiary_of.csv: ['child_company_id', 'parent_company_id', 'since_year']\n",
      "  âœ… 224 SUBSIDIARY_OF relationships created\n",
      "\n",
      "ðŸšš Creating SUPPLIES relationships...\n",
      "  ðŸ“‹ Columns in supplies.csv: ['supplier_company_id', 'buyer_company_id', 'annual_volume']\n",
      "  âœ… 359 SUPPLIES relationships created\n",
      "\n",
      "================================================================================\n",
      "PHASE 3: CREATING INDEXES\n",
      "================================================================================\n",
      "  âœ… CREATE INDEX company_id_idx\n",
      "  âœ… CREATE INDEX shareholder_id_idx\n",
      "  âœ… CREATE INDEX auditor_id_idx\n",
      "  âœ… CREATE INDEX invoice_id_idx\n",
      "  âœ… CREATE INDEX company_risk_idx\n",
      "  âœ… CREATE INDEX auditor_risk_idx\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š GRAPH SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Nodes:\n",
      "  â€¢ Invoice: 1,500\n",
      "  â€¢ Company: 500\n",
      "  â€¢ Shareholder: 250\n",
      "  â€¢ Auditor: 10\n",
      "\n",
      "Relationships:\n",
      "  â€¢ OWNS_SHARE: 1,777\n",
      "  â€¢ ISSUES_TO: 1,500\n",
      "  â€¢ PAYS: 1,490\n",
      "  â€¢ AUDITED_BY: 500\n",
      "  â€¢ SUPPLIES: 359\n",
      "  â€¢ SUBSIDIARY_OF: 223\n",
      "\n",
      "================================================================================\n",
      "TOTALS: 2,260 nodes, 5,849 relationships\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ðŸ” VALIDATION CHECKS\n",
      "================================================================================\n",
      "\n",
      "âœ“ High-risk auditors: 2\n",
      "âœ“ Companies with parent companies: 182\n",
      "âœ“ Supply relationships: 359\n",
      "âœ“ Sample circular supply patterns found: 6\n",
      "âœ“ Ownership stakes >25%: 633\n",
      "\n",
      "================================================================================\n",
      "ðŸŽ‰ INGESTION COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Next steps:\n",
      "  1. Open Neo4j Browser at http://localhost:7474\n",
      "  2. Run: CALL db.schema.visualization()\n",
      "  3. Start detecting fraud patterns!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class Neo4jIngester:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def run_query(self, query, parameters=None):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query, parameters)\n",
    "            return result\n",
    "\n",
    "def clean_dataframe(df, id_cols):\n",
    "    \"\"\"Clean dataframe by removing rows with null/NaN in ID columns\"\"\"\n",
    "    initial_count = len(df)\n",
    "    df = df.dropna(subset=id_cols)\n",
    "    removed = initial_count - len(df)\n",
    "    if removed > 0:\n",
    "        print(f\"  âš ï¸  Removed {removed} rows with null IDs\")\n",
    "    \n",
    "    # Convert ID columns to string and strip whitespace\n",
    "    for col in id_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def ingest_data():\n",
    "    # Neo4j connection parameters - UPDATE THESE\n",
    "    NEO4J_URI = \"bolt://localhost:7687\"\n",
    "    NEO4J_USER = \"neo4j\" \n",
    "    NEO4J_PASSWORD = \"password\"  # CHANGE THIS\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ðŸš€ STARTING NEO4J DATA INGESTION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    ingester = Neo4jIngester(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "    \n",
    "    # Clear existing data\n",
    "    print(\"\\nðŸ—‘ï¸  Clearing existing data...\")\n",
    "    ingester.run_query(\"MATCH (n) DETACH DELETE n\")\n",
    "    print(\"  âœ… Database cleared\")\n",
    "    \n",
    "    folder_path = 'output_csv/'\n",
    "    \n",
    "    # ==================================================================\n",
    "    # 1. INGEST NODE ENTITIES\n",
    "    # ==================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PHASE 1: INGESTING NODES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Companies\n",
    "    print(\"\\nðŸ¢ Ingesting Companies...\")\n",
    "    companies_df = pd.read_csv(os.path.join(folder_path, 'companies.csv'))\n",
    "    companies_df = clean_dataframe(companies_df, ['company_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MERGE (c:Company {company_id: row.company_id})\n",
    "    SET c.name = row.name,\n",
    "        c.country = row.country,\n",
    "        c.sector = row.sector,\n",
    "        c.risk_score = toFloat(row.risk_score),\n",
    "        c.opportunity_score = toFloat(row.opportunity_score),\n",
    "        c.is_supplier = CASE WHEN row.is_supplier = 'True' THEN true ELSE false END\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': companies_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(companies_df)} companies ingested\")\n",
    "    \n",
    "    # Auditors\n",
    "    print(\"\\nðŸ‘® Ingesting Auditors...\")\n",
    "    auditors_df = pd.read_csv(os.path.join(folder_path, 'auditors.csv'))\n",
    "    auditors_df = clean_dataframe(auditors_df, ['auditor_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MERGE (a:Auditor {auditor_id: row.auditor_id})\n",
    "    SET a.name = row.name,\n",
    "        a.risk_level = row.risk_level\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': auditors_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(auditors_df)} auditors ingested\")\n",
    "    \n",
    "    # Shareholders\n",
    "    print(\"\\nðŸ’¼ Ingesting Shareholders...\")\n",
    "    shareholders_df = pd.read_csv(os.path.join(folder_path, 'shareholders.csv'))\n",
    "    shareholders_df = clean_dataframe(shareholders_df, ['shareholder_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MERGE (s:Shareholder {shareholder_id: row.shareholder_id})\n",
    "    SET s.name = row.name,\n",
    "        s.type = row.type,\n",
    "        s.risk_score = toFloat(row.risk_score),\n",
    "        s.opportunity_score = toFloat(row.opportunity_score)\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': shareholders_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(shareholders_df)} shareholders ingested\")\n",
    "    \n",
    "    # Invoices\n",
    "    print(\"\\nðŸ“„ Ingesting Invoices...\")\n",
    "    invoices_df = pd.read_csv(os.path.join(folder_path, 'invoices.csv'))\n",
    "    invoices_df = clean_dataframe(invoices_df, ['invoice_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MERGE (i:Invoice {invoice_id: row.invoice_id})\n",
    "    SET i.amount = toFloat(row.amount),\n",
    "        i.status = row.status,\n",
    "        i.is_simulated = CASE WHEN row.is_simulated = 'True' THEN true ELSE false END\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': invoices_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(invoices_df)} invoices ingested\")\n",
    "    \n",
    "    # ==================================================================\n",
    "    # 2. INGEST RELATIONSHIPS - USING CORRECT COLUMN NAMES\n",
    "    # ==================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PHASE 2: CREATING RELATIONSHIPS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # OWNS_SHARE (shareholder_id, company_id, percentage)\n",
    "    print(\"\\nðŸ“ˆ Creating OWNS_SHARE relationships...\")\n",
    "    owns_share_df = pd.read_csv(os.path.join(folder_path, 'owns_share.csv'))\n",
    "    owns_share_df = clean_dataframe(owns_share_df, ['shareholder_id', 'company_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MATCH (s:Shareholder {shareholder_id: row.shareholder_id})\n",
    "    MATCH (c:Company {company_id: row.company_id})\n",
    "    MERGE (s)-[r:OWNS_SHARE]->(c)\n",
    "    SET r.percentage = toFloat(row.percentage)\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': owns_share_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(owns_share_df)} OWNS_SHARE relationships created\")\n",
    "    \n",
    "    # AUDITED_BY (company_id, auditor_id)\n",
    "    print(\"\\nðŸ” Creating AUDITED_BY relationships...\")\n",
    "    audited_by_df = pd.read_csv(os.path.join(folder_path, 'audited_by.csv'))\n",
    "    audited_by_df = clean_dataframe(audited_by_df, ['company_id', 'auditor_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MATCH (c:Company {company_id: row.company_id})\n",
    "    MATCH (a:Auditor {auditor_id: row.auditor_id})\n",
    "    MERGE (c)-[r:AUDITED_BY]->(a)\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': audited_by_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(audited_by_df)} AUDITED_BY relationships created\")\n",
    "    \n",
    "    # ISSUES_TO (company_id, invoice_id)\n",
    "    print(\"\\nðŸ“¤ Creating ISSUES_TO relationships...\")\n",
    "    issues_to_df = pd.read_csv(os.path.join(folder_path, 'issues_to.csv'))\n",
    "    issues_to_df = clean_dataframe(issues_to_df, ['company_id', 'invoice_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MATCH (c:Company {company_id: row.company_id})\n",
    "    MATCH (i:Invoice {invoice_id: row.invoice_id})\n",
    "    MERGE (c)-[r:ISSUES_TO]->(i)\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': issues_to_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(issues_to_df)} ISSUES_TO relationships created\")\n",
    "    \n",
    "    # PAYS (company_id, invoice_id)\n",
    "    print(\"\\nðŸ’³ Creating PAYS relationships...\")\n",
    "    pays_df = pd.read_csv(os.path.join(folder_path, 'pays.csv'))\n",
    "    pays_df = clean_dataframe(pays_df, ['company_id', 'invoice_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MATCH (c:Company {company_id: row.company_id})\n",
    "    MATCH (i:Invoice {invoice_id: row.invoice_id})\n",
    "    MERGE (c)-[r:PAYS]->(i)\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': pays_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(pays_df)} PAYS relationships created\")\n",
    "    \n",
    "    # SUBSIDIARY_OF (child_company_id, parent_company_id, since_year)\n",
    "    print(\"\\nðŸ¢ Creating SUBSIDIARY_OF relationships...\")\n",
    "    subsidiary_df = pd.read_csv(os.path.join(folder_path, 'subsidiary_of.csv'))\n",
    "    print(f\"  ðŸ“‹ Columns in subsidiary_of.csv: {list(subsidiary_df.columns)}\")\n",
    "    subsidiary_df = clean_dataframe(subsidiary_df, ['child_company_id', 'parent_company_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MATCH (child:Company {company_id: row.child_company_id})\n",
    "    MATCH (parent:Company {company_id: row.parent_company_id})\n",
    "    MERGE (child)-[r:SUBSIDIARY_OF]->(parent)\n",
    "    SET r.since_year = toInteger(row.since_year)\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': subsidiary_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(subsidiary_df)} SUBSIDIARY_OF relationships created\")\n",
    "    \n",
    "    # SUPPLIES (supplier_company_id, buyer_company_id, annual_volume)\n",
    "    print(\"\\nðŸšš Creating SUPPLIES relationships...\")\n",
    "    supplies_df = pd.read_csv(os.path.join(folder_path, 'supplies.csv'))\n",
    "    print(f\"  ðŸ“‹ Columns in supplies.csv: {list(supplies_df.columns)}\")\n",
    "    supplies_df = clean_dataframe(supplies_df, ['supplier_company_id', 'buyer_company_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MATCH (supplier:Company {company_id: row.supplier_company_id})\n",
    "    MATCH (buyer:Company {company_id: row.buyer_company_id})\n",
    "    MERGE (supplier)-[r:SUPPLIES]->(buyer)\n",
    "    SET r.annual_volume = toFloat(row.annual_volume)\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': supplies_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(supplies_df)} SUPPLIES relationships created\")\n",
    "    \n",
    "    # ==================================================================\n",
    "    # 3. CREATE INDEXES FOR PERFORMANCE\n",
    "    # ==================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PHASE 3: CREATING INDEXES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    indexes = [\n",
    "        \"CREATE INDEX company_id_idx IF NOT EXISTS FOR (c:Company) ON (c.company_id)\",\n",
    "        \"CREATE INDEX shareholder_id_idx IF NOT EXISTS FOR (s:Shareholder) ON (s.shareholder_id)\",\n",
    "        \"CREATE INDEX auditor_id_idx IF NOT EXISTS FOR (a:Auditor) ON (a.auditor_id)\",\n",
    "        \"CREATE INDEX invoice_id_idx IF NOT EXISTS FOR (i:Invoice) ON (i.invoice_id)\",\n",
    "        \"CREATE INDEX company_risk_idx IF NOT EXISTS FOR (c:Company) ON (c.risk_score)\",\n",
    "        \"CREATE INDEX auditor_risk_idx IF NOT EXISTS FOR (a:Auditor) ON (a.risk_level)\"\n",
    "    ]\n",
    "    \n",
    "    for idx_query in indexes:\n",
    "        try:\n",
    "            ingester.run_query(idx_query)\n",
    "            print(f\"  âœ… {idx_query.split('FOR')[0].split('IF')[0].strip()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸  Index creation skipped (may already exist)\")\n",
    "    \n",
    "    # ==================================================================\n",
    "    # 4. GRAPH SUMMARY\n",
    "    # ==================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ðŸ“Š GRAPH SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Count nodes by label\n",
    "    with ingester.driver.session() as session:\n",
    "        # Node counts\n",
    "        node_query = \"\"\"\n",
    "        MATCH (n)\n",
    "        RETURN labels(n)[0] as label, count(n) as count\n",
    "        ORDER BY count DESC\n",
    "        \"\"\"\n",
    "        result = session.run(node_query)\n",
    "        print(\"\\nNodes:\")\n",
    "        for record in result:\n",
    "            print(f\"  â€¢ {record['label']}: {record['count']:,}\")\n",
    "        \n",
    "        # Relationship counts\n",
    "        rel_query = \"\"\"\n",
    "        MATCH ()-[r]->()\n",
    "        RETURN type(r) as type, count(r) as count\n",
    "        ORDER BY count DESC\n",
    "        \"\"\"\n",
    "        result = session.run(rel_query)\n",
    "        print(\"\\nRelationships:\")\n",
    "        for record in result:\n",
    "            print(f\"  â€¢ {record['type']}: {record['count']:,}\")\n",
    "        \n",
    "        # Total counts\n",
    "        total_query = \"\"\"\n",
    "        MATCH (n)\n",
    "        WITH count(n) as nodeCount\n",
    "        MATCH ()-[r]->()\n",
    "        RETURN nodeCount, count(r) as relCount\n",
    "        \"\"\"\n",
    "        result = session.run(total_query)\n",
    "        record = result.single()\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"TOTALS: {record['nodeCount']:,} nodes, {record['relCount']:,} relationships\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "    \n",
    "    # ==================================================================\n",
    "    # 5. VALIDATION QUERIES\n",
    "    # ==================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ðŸ” VALIDATION CHECKS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    with ingester.driver.session() as session:\n",
    "        # Check for high-risk auditors\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (a:Auditor)\n",
    "            WHERE a.risk_level = 'HIGH'\n",
    "            RETURN count(a) as count\n",
    "        \"\"\")\n",
    "        high_risk = result.single()['count']\n",
    "        print(f\"\\nâœ“ High-risk auditors: {high_risk}\")\n",
    "        \n",
    "        # Check for companies with subsidiaries\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (c:Company)-[:SUBSIDIARY_OF]->()\n",
    "            RETURN count(DISTINCT c) as count\n",
    "        \"\"\")\n",
    "        subs = result.single()['count']\n",
    "        print(f\"âœ“ Companies with parent companies: {subs}\")\n",
    "        \n",
    "        # Check for supply relationships\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH ()-[r:SUPPLIES]->()\n",
    "            RETURN count(r) as count\n",
    "        \"\"\")\n",
    "        supplies = result.single()['count']\n",
    "        print(f\"âœ“ Supply relationships: {supplies}\")\n",
    "        \n",
    "        # Check for circular patterns (sample)\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH path = (c1:Company)-[:SUPPLIES]->(c2:Company)-[:SUPPLIES]->(c3:Company)-[:SUPPLIES]->(c1)\n",
    "            RETURN count(path) as count\n",
    "            LIMIT 100\n",
    "        \"\"\")\n",
    "        cycles = result.single()['count']\n",
    "        print(f\"âœ“ Sample circular supply patterns found: {cycles}\")\n",
    "        \n",
    "        # Check for ownership concentration\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (s:Shareholder)-[o:OWNS_SHARE]->(c:Company)\n",
    "            WHERE o.percentage > 25\n",
    "            RETURN count(o) as count\n",
    "        \"\"\")\n",
    "        major_stakes = result.single()['count']\n",
    "        print(f\"âœ“ Ownership stakes >25%: {major_stakes}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ðŸŽ‰ INGESTION COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"  1. Open Neo4j Browser at http://localhost:7474\")\n",
    "    print(\"  2. Run: CALL db.schema.visualization()\")\n",
    "    print(\"  3. Start detecting fraud patterns!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    ingester.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        ingest_data()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ERROR: {str(e)}\")\n",
    "        print(\"\\nMake sure:\")\n",
    "        print(\"  1. Neo4j is running (check localhost:7474)\")\n",
    "        print(\"  2. Credentials are correct\")\n",
    "        print(\"  3. CSV files exist in output_csv/ folder\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d2302b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82feb9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90add6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40fa5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc0583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d898c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045f2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390f079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—‘ï¸  Clearing existing data...\n",
      "\n",
      "ðŸ¢ Ingesting Companies...\n",
      "  Removed 0 rows with null IDs\n",
      "  âœ… 500 companies ingested\n",
      "\n",
      "ðŸ‘® Ingesting Auditors...\n",
      "  Removed 0 rows with null IDs\n",
      "  âœ… 10 auditors ingested\n",
      "\n",
      "ðŸ’¼ Ingesting Shareholders...\n",
      "  Removed 0 rows with null IDs\n",
      "  âœ… 250 shareholders ingested\n",
      "\n",
      "ðŸ“„ Ingesting Invoices...\n",
      "  Removed 0 rows with null IDs\n",
      "  âœ… 1500 invoices ingested\n",
      "\n",
      "ðŸ“ˆ Creating OWNS_SHARE relationships...\n",
      "  Removed 0 rows with null IDs\n",
      "  âœ… 1766 OWNS_SHARE relationships\n",
      "ðŸ” Creating AUDITED_BY relationships...\n",
      "  Removed 0 rows with null IDs\n",
      "  âœ… 500 AUDITED_BY relationships\n",
      "ðŸ“¤ Creating ISSUES_TO relationships...\n",
      "  Removed 0 rows with null IDs\n",
      "  âœ… 1500 ISSUES_TO relationships\n",
      "ðŸ’³ Creating PAYS relationships...\n",
      "  Removed 0 rows with null IDs\n",
      "  âœ… 1490 PAYS relationships\n",
      "ðŸ¢ Creating SUBSIDIARY_OF relationships...\n",
      "  Removed 0 rows with null IDs\n",
      "  âœ… 215 SUBSIDIARY_OF relationships\n",
      "ðŸšš Creating SUPPLIES relationships...\n",
      "  Removed 0 rows with null IDs\n",
      "  âœ… 362 SUPPLIES relationships\n",
      "\n",
      "ðŸŽ‰ COMPLETE INGESTION SUCCESSFUL!\n",
      "\n",
      "ðŸ“Š GRAPH SUMMARY:\n",
      "  Run `CALL db.labels()` and `CALL db.relationshipTypes()` in Neo4j Browser\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class Neo4jIngester:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def run_query(self, query, parameters=None):\n",
    "        with self.driver.session() as session:\n",
    "            session.run(query, parameters)\n",
    "\n",
    "def clean_dataframe(df, id_cols):\n",
    "    \"\"\"Clean dataframe by removing rows with null/NaN in ID columns\"\"\"\n",
    "    initial_count = len(df)\n",
    "    df = df.dropna(subset=id_cols)\n",
    "    print(f\"  Removed {initial_count - len(df)} rows with null IDs\")\n",
    "    \n",
    "    # Convert ID columns to string\n",
    "    for col in id_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def ingest_data():\n",
    "    # Neo4j connection parameters - UPDATE THESE\n",
    "    NEO4J_URI = \"bolt://localhost:7687\"\n",
    "    NEO4J_USER = \"neo4j\" \n",
    "    NEO4J_PASSWORD = \"password\"\n",
    "    \n",
    "    ingester = Neo4jIngester(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "    \n",
    "    # Clear existing data\n",
    "    print(\"ðŸ—‘ï¸  Clearing existing data...\")\n",
    "    ingester.run_query(\"MATCH (n) DETACH DELETE n\")\n",
    "    \n",
    "    folder_path = 'output_csv/'\n",
    "    \n",
    "    # 1. INGEST NODES - Using EXACT CSV column names\n",
    "    \n",
    "    # Companies\n",
    "    print(\"\\nðŸ¢ Ingesting Companies...\")\n",
    "    companies_df = pd.read_csv(os.path.join(folder_path, 'companies.csv'))\n",
    "    companies_df = clean_dataframe(companies_df, ['company_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MERGE (c:Company {company_id: row.company_id})\n",
    "    SET c.name = row.name,\n",
    "        c.country = row.country,\n",
    "        c.sector = row.sector,\n",
    "        c.risk_score = toFloat(row.risk_score),\n",
    "        c.opportunity_score = toFloat(row.opportunity_score),\n",
    "        c.is_supplier = row.is_supplier = 'True'\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': companies_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(companies_df)} companies ingested\")\n",
    "    \n",
    "    # Auditors\n",
    "    print(\"\\nðŸ‘® Ingesting Auditors...\")\n",
    "    auditors_df = pd.read_csv(os.path.join(folder_path, 'auditors.csv'))\n",
    "    auditors_df = clean_dataframe(auditors_df, ['auditor_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MERGE (a:Auditor {auditor_id: row.auditor_id})\n",
    "    SET a.name = row.name,\n",
    "        a.risk_level = row.risk_level\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': auditors_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(auditors_df)} auditors ingested\")\n",
    "    \n",
    "    # Shareholders\n",
    "    print(\"\\nðŸ’¼ Ingesting Shareholders...\")\n",
    "    shareholders_df = pd.read_csv(os.path.join(folder_path, 'shareholders.csv'))\n",
    "    shareholders_df = clean_dataframe(shareholders_df, ['shareholder_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MERGE (s:Shareholder {shareholder_id: row.shareholder_id})\n",
    "    SET s.name = row.name,\n",
    "        s.type = row.type,\n",
    "        s.risk_score = toFloat(row.risk_score),\n",
    "        s.opportunity_score = toFloat(row.opportunity_score)\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': shareholders_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(shareholders_df)} shareholders ingested\")\n",
    "    \n",
    "    # Invoices\n",
    "    print(\"\\nðŸ“„ Ingesting Invoices...\")\n",
    "    invoices_df = pd.read_csv(os.path.join(folder_path, 'invoices.csv'))\n",
    "    invoices_df = clean_dataframe(invoices_df, ['invoice_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MERGE (i:Invoice {invoice_id: row.invoice_id})\n",
    "    SET i.amount = toFloat(row.amount),\n",
    "        i.status = row.status,\n",
    "        i.is_simulated = row.is_simulated = 'True'\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': invoices_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(invoices_df)} invoices ingested\")\n",
    "    \n",
    "    # 2. INGEST RELATIONSHIPS - Using EXACT CSV column names\n",
    "    \n",
    "    # owns_share\n",
    "    print(\"\\nðŸ“ˆ Creating OWNS_SHARE relationships...\")\n",
    "    owns_share_df = pd.read_csv(os.path.join(folder_path, 'owns_share.csv'))\n",
    "    owns_share_df = clean_dataframe(owns_share_df, ['shareholder_id', 'company_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MATCH (s:Shareholder {shareholder_id: row.shareholder_id})\n",
    "    MATCH (c:Company {company_id: row.company_id})\n",
    "    MERGE (s)-[r:OWNS_SHARE]->(c)\n",
    "    SET r.shares = toFloat(coalesce(row.shares, 0)),\n",
    "        r.percentage = toFloat(coalesce(row.percentage, 0))\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': owns_share_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(owns_share_df)} OWNS_SHARE relationships\")\n",
    "    \n",
    "    # audited_by\n",
    "    print(\"ðŸ” Creating AUDITED_BY relationships...\")\n",
    "    audited_by_df = pd.read_csv(os.path.join(folder_path, 'audited_by.csv'))\n",
    "    audited_by_df = clean_dataframe(audited_by_df, ['company_id', 'auditor_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MATCH (c:Company {company_id: row.company_id})\n",
    "    MATCH (a:Auditor {auditor_id: row.auditor_id})\n",
    "    MERGE (c)-[r:AUDITED_BY]->(a)\n",
    "    SET r.since_year = toInteger(coalesce(row.since_year, 0))\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': audited_by_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(audited_by_df)} AUDITED_BY relationships\")\n",
    "    \n",
    "    # issues_to\n",
    "    print(\"ðŸ“¤ Creating ISSUES_TO relationships...\")\n",
    "    issues_to_df = pd.read_csv(os.path.join(folder_path, 'issues_to.csv'))\n",
    "    issues_to_df = clean_dataframe(issues_to_df, ['company_id', 'invoice_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MATCH (c:Company {company_id: row.company_id})\n",
    "    MATCH (i:Invoice {invoice_id: row.invoice_id})\n",
    "    MERGE (c)-[r:ISSUES_TO]->(i)\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': issues_to_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(issues_to_df)} ISSUES_TO relationships\")\n",
    "    \n",
    "    # pays\n",
    "    print(\"ðŸ’³ Creating PAYS relationships...\")\n",
    "    pays_df = pd.read_csv(os.path.join(folder_path, 'pays.csv'))\n",
    "    pays_df = clean_dataframe(pays_df, ['company_id', 'invoice_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MATCH (c:Company {company_id: row.company_id})\n",
    "    MATCH (i:Invoice {invoice_id: row.invoice_id})\n",
    "    MERGE (c)-[r:PAYS]->(i)\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': pays_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(pays_df)} PAYS relationships\")\n",
    "    \n",
    "    # subsidiary_of\n",
    "    print(\"ðŸ¢ Creating SUBSIDIARY_OF relationships...\")\n",
    "    subsidiary_df = pd.read_csv(os.path.join(folder_path, 'subsidiary_of.csv'))\n",
    "    subsidiary_df = clean_dataframe(subsidiary_df, ['company_id', 'company_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MATCH (child:Company {company_id: row.company_id})\n",
    "    MATCH (parent:Company {company_id: row.company_id})\n",
    "    MERGE (child)-[r:SUBSIDIARY_OF]->(parent)\n",
    "    SET r.since_year = toInteger(coalesce(row.since_year, 0))\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': subsidiary_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(subsidiary_df)} SUBSIDIARY_OF relationships\")\n",
    "    \n",
    "    # supplies\n",
    "    print(\"ðŸšš Creating SUPPLIES relationships...\")\n",
    "    supplies_df = pd.read_csv(os.path.join(folder_path, 'supplies.csv'))\n",
    "    supplies_df = clean_dataframe(supplies_df, ['company_id', 'company_id'])\n",
    "    query = \"\"\"\n",
    "    UNWIND $rows as row\n",
    "    MATCH (supplier:Company {company_id: row.company_id})\n",
    "    MATCH (customer:Company {company_id: row.company_id})\n",
    "    MERGE (supplier)-[r:SUPPLIES]->(customer)\n",
    "    SET r.annual_volume = toFloat(coalesce(row.annual_volume, 0))\n",
    "    \"\"\"\n",
    "    ingester.run_query(query, {'rows': supplies_df.to_dict('records')})\n",
    "    print(f\"  âœ… {len(supplies_df)} SUPPLIES relationships\")\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ COMPLETE INGESTION SUCCESSFUL!\")\n",
    "    \n",
    "    # Graph Summary\n",
    "    print(\"\\nðŸ“Š GRAPH SUMMARY:\")\n",
    "    summary_query = \"\"\"\n",
    "    MATCH (n)\n",
    "    RETURN apoc.label.names(n) as labels, count(n) as count\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with ingester.driver.session() as session:\n",
    "            result = session.run(summary_query)\n",
    "            for record in result:\n",
    "                print(f\"  {record['labels']}: {record['count']}\")\n",
    "    except:\n",
    "        # Fallback summary\n",
    "        print(\"  Run `CALL db.labels()` and `CALL db.relationshipTypes()` in Neo4j Browser\")\n",
    "    \n",
    "    ingester.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ingest_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37055c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud_detection_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
